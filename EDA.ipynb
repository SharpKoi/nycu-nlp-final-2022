{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa21810",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbddd9ac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b19983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f0079",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb797746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_0512.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7ece4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462be9db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_id_counts = df.value_counts('conv_id')\n",
    "conv_id_counts[conv_id_counts == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['conv_id'] == 'hit:2444_conv:4888']['utterance'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0c8d2",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- [x] replace \"\\_comma\\_\" with \",\"\n",
    "- [x] remove punctuations\n",
    "- [x] to lower case\n",
    "- [x] concatenate the whole conversation grouped by `conv_id` with token \"[SEP]\" joined\n",
    "- [x] prepend \"[CLS]\"\n",
    "- [x] append sentimental text label\n",
    "- [ ] correct spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5535d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"_comma_\" with \",\"\n",
    "df.loc[:, 'prompt'] = df['prompt'].str.replace('_comma_', ',').str.lower()\n",
    "df.loc[:, 'utterance'] = df['utterance'].str.replace('_comma_', ',').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7096cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove punctuations\n",
    "import re, string\n",
    "\n",
    "def remove_punctuations(text: str):\n",
    "    punc_filter = re.compile(f'[{string.punctuation}]')\n",
    "    return punc_filter.sub(' ', text)\n",
    "    \n",
    "df.loc[:, 'prompt'] = df['prompt'].apply(remove_punctuations)\n",
    "df.loc[:, 'utterance'] = df['utterance'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id = {\n",
    "    'sad':      0,  'trusting':     1,  'terrified': 2,  'caring':      3,  'disappointed': 4, \n",
    "    'faithful': 5,  'joyful':       6,  'jealous':   7,  'disgusted':   8,  'surprised':    9, \n",
    "    'ashamed':  10, 'afraid':       11, 'impressed': 12, 'sentimental': 13, 'devastated':   14, \n",
    "    'excited':  15, 'anticipating': 16, 'annoyed':   17, 'anxious':     18, 'furious':      19, \n",
    "    'content':  20, 'lonely':       21, 'angry':     22, 'confident':   23, 'apprehensive': 24, \n",
    "    'guilty':   25, 'embarrassed':  26, 'grateful':  27, 'hopeful':     28, 'proud':        29, \n",
    "    'prepared': 30, 'nostalgic':    31\n",
    "}\n",
    "\n",
    "id_sent = {v: k for k, v in sent_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate conversations and append sentiment text label\n",
    "df_concat = pd.DataFrame(columns=df.columns.to_list() + ['sent']) \\\n",
    "            .drop(['id', 'utterance_idx'], axis=1) \\\n",
    "            .rename(columns={'utterance': 'conv'})\n",
    "\n",
    "conv_id_groups = df.groupby(['conv_id'])\n",
    "\n",
    "for _, indices in tqdm(conv_id_groups.groups.items()):\n",
    "    conv_rows = df.loc[indices].copy().sort_values(['utterance_idx'])\n",
    "    conv_row = conv_rows.iloc[0].drop(['id', 'utterance_idx']).rename({'utterance': 'conv'})\n",
    "    conv_row['prompt'] = '[CLS] ' + conv_row['prompt'] + ' [SEP]'\n",
    "    conv_row['conv'] = '[CLS] ' + ' [SEP] '.join(conv_rows['utterance'].values)\n",
    "    conv_row['sent'] = id_sent[conv_row['label']]\n",
    "    df_concat = df_concat.append(conv_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a2a3e",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "- [x] count each label, check classes imbalance\n",
    "- [ ] check the words with high frequencies for each label\n",
    "- [ ] check the label similarities (maybe by common words counts)\n",
    "- [ ] data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ce9f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sent_tiers = pd.DataFrame(df_concat.value_counts(subset=['sent']), columns=['count']) \\\n",
    "            .sort_values('count').reset_index()\n",
    "px.bar(sent_tiers, x='count', y='sent', color='count', \n",
    "       title='Label Counts', width=800, height=800,\n",
    "       color_continuous_scale=px.colors.sequential.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2123f05",
   "metadata": {},
   "source": [
    "The classes are not quite imbalanced. But the samples with `surprised` label are far more than others.  \n",
    "we may need data augmentation for other labels excluding `surprised` label.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "vocab = set()\n",
    "prompt_tokens, conv_tokens = list(), list()\n",
    "\n",
    "for prompt in df_concat['prompt'].values:\n",
    "    tokens = prompt.split()\n",
    "    vocab = vocab.union(set(tokens))\n",
    "    prompt_tokens.append(tokens)\n",
    "    \n",
    "for conv in df_concat['conv'].values:\n",
    "    tokens = conv.split()\n",
    "    vocab = vocab.union(set(tokens))\n",
    "    conv_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "seqlens_prompt = np.array([len(tokens) for tokens in prompt_tokens])\n",
    "print(f'# of vocab: {len(vocab)}')\n",
    "print('=== Tokenized Prompt Corpus ===')\n",
    "print(f'max sequence length: {seqlens_prompt.max()}')\n",
    "print(f'min sequence length: {seqlens_prompt.min()}')\n",
    "print(f'avg sequence length: {seqlens_prompt.mean()}\\n')\n",
    "\n",
    "seqlens_conv = np.array([len(tokens) for tokens in conv_tokens])\n",
    "print('=== Tokenized Conversation Corpus ===')\n",
    "print(f'max sequence length: {seqlens_conv.max()}')\n",
    "print(f'min sequence length: {seqlens_conv.min()}')\n",
    "print(f'avg sequence length: {seqlens_conv.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a794149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.where(seqlens_conv >= 512)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "palette = iter([plt.cm.Accent(i) for i in range(10)])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist([len(prompt) for prompt in prompt_tokens], range=(1, 513), color=next(palette))\n",
    "plt.title('Prompt Corpus Sequences Length Histogram', fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist([len(conv) for conv in conv_tokens], range=(1, 513), color=next(palette))\n",
    "plt.title('Conversation Corpus Sequences Length Histogram', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932d69c",
   "metadata": {},
   "source": [
    "## Proposal\n",
    "- Use BERT to infer `prompt` & `utterance` representationsï¼Œconcatenate the two hypotheses.\n",
    "- Add a `LayerNorm` layer to receive the concatenated result.\n",
    "- Use `Linear` layer to do classification.\n",
    "- Maybe we can use `SAM` to smooth the loss landscape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
