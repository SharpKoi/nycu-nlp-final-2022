{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128b3cb3",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4dd70a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b19983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5af4de",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a08349",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('data/fixed_train.csv')\n",
    "validdf = pd.read_csv('data/fixed_valid.csv')\n",
    "testdf = pd.read_csv('data/fixed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6adcc65d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>prompt</th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>4</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>5</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84164</th>\n",
       "      <td>hit:12424_conv:24848</td>\n",
       "      <td>5</td>\n",
       "      <td>I found some pictures of my grandma in the att...</td>\n",
       "      <td>Yeah reminds me of the good old days.  I miss ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84165</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>1</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84166</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>2</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>Oh hey that's awesome!  That is awesome right?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84167</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>3</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>It is soooo awesome.  We have been wanting a b...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84168</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>4</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>That is awesome!!!! Congratulations!</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84169 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conv_id  utterance_idx  \\\n",
       "0              hit:0_conv:1              1   \n",
       "1              hit:0_conv:1              2   \n",
       "2              hit:0_conv:1              3   \n",
       "3              hit:0_conv:1              4   \n",
       "4              hit:0_conv:1              5   \n",
       "...                     ...            ...   \n",
       "84164  hit:12424_conv:24848              5   \n",
       "84165  hit:12424_conv:24849              1   \n",
       "84166  hit:12424_conv:24849              2   \n",
       "84167  hit:12424_conv:24849              3   \n",
       "84168  hit:12424_conv:24849              4   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      I remember going to the fireworks with my best...   \n",
       "1      I remember going to the fireworks with my best...   \n",
       "2      I remember going to the fireworks with my best...   \n",
       "3      I remember going to the fireworks with my best...   \n",
       "4      I remember going to the fireworks with my best...   \n",
       "...                                                  ...   \n",
       "84164  I found some pictures of my grandma in the att...   \n",
       "84165  I woke up this morning to my wife telling me s...   \n",
       "84166  I woke up this morning to my wife telling me s...   \n",
       "84167  I woke up this morning to my wife telling me s...   \n",
       "84168  I woke up this morning to my wife telling me s...   \n",
       "\n",
       "                                               utterance  label  \n",
       "0      I remember going to see the fireworks with my ...     13  \n",
       "1      Was this a friend you were in love with_comma_...     13  \n",
       "2                    This was a best friend. I miss her.     13  \n",
       "3                                    Where has she gone?     13  \n",
       "4                                     We no longer talk.     13  \n",
       "...                                                  ...    ...  \n",
       "84164  Yeah reminds me of the good old days.  I miss ...     13  \n",
       "84165  I woke up this morning to my wife telling me s...      9  \n",
       "84166     Oh hey that's awesome!  That is awesome right?      9  \n",
       "84167  It is soooo awesome.  We have been wanting a b...      9  \n",
       "84168               That is awesome!!!! Congratulations!      9  \n",
       "\n",
       "[84169 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbce96",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- [x] replace \"\\_comma\\_\" with \",\"\n",
    "- [x] remove punctuations\n",
    "- [x] to lower case\n",
    "- [x] concatenate the whole conversation grouped by `conv_id` with token \"[SEP]\" joined\n",
    "- [x] prepend \"[CLS]\"\n",
    "- [x] append sentimental text label\n",
    "- [ ] correct spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882d4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"_comma_\" with \",\"\n",
    "def replace_comma(df):\n",
    "    df.loc[:, 'prompt'] = df['prompt'].str.replace('_comma_', ',')\n",
    "    df.loc[:, 'utterance'] = df['utterance'].str.replace('_comma_', ',')\n",
    "\n",
    "replace_comma(traindf)\n",
    "replace_comma(validdf)\n",
    "replace_comma(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03bdb458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove punctuations\n",
    "import re, string\n",
    "\n",
    "def remove_punctuations(text: str):\n",
    "    punc_filter = re.compile(f'[{string.punctuation}]')\n",
    "    return punc_filter.sub(' ', text)\n",
    "    \n",
    "traindf.loc[:, 'prompt'] = traindf['prompt'].apply(remove_punctuations)\n",
    "traindf.loc[:, 'utterance'] = traindf['utterance'].apply(remove_punctuations)\n",
    "validdf.loc[:, 'prompt'] = validdf['prompt'].apply(remove_punctuations)\n",
    "validdf.loc[:, 'utterance'] = validdf['utterance'].apply(remove_punctuations)\n",
    "testdf.loc[:, 'prompt'] = testdf['prompt'].apply(remove_punctuations)\n",
    "testdf.loc[:, 'utterance'] = testdf['utterance'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95bbec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "def lowercase(df):\n",
    "    df.loc[:, 'prompt'] = df['prompt'].str.lower()\n",
    "    df.loc[:, 'utterance'] = df['utterance'].str.lower()\n",
    "    \n",
    "lowercase(traindf)\n",
    "lowercase(validdf)\n",
    "lowercase(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d6f7cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# append sentiment text label\n",
    "sent_id = {\n",
    "    'sad':      0,  'trusting':     1,  'terrified': 2,  'caring':      3,  'disappointed': 4, \n",
    "    'faithful': 5,  'joyful':       6,  'jealous':   7,  'disgusted':   8,  'surprised':    9, \n",
    "    'ashamed':  10, 'afraid':       11, 'impressed': 12, 'sentimental': 13, 'devastated':   14, \n",
    "    'excited':  15, 'anticipating': 16, 'annoyed':   17, 'anxious':     18, 'furious':      19, \n",
    "    'content':  20, 'lonely':       21, 'angry':     22, 'confident':   23, 'apprehensive': 24, \n",
    "    'guilty':   25, 'embarrassed':  26, 'grateful':  27, 'hopeful':     28, 'proud':        29, \n",
    "    'prepared': 30, 'nostalgic':    31\n",
    "}\n",
    "\n",
    "id_sent = {v: k for k, v in sent_id.items()}\n",
    "\n",
    "def append_sent(df):\n",
    "    df['sent'] = df['label'].apply(id_sent.get)\n",
    "\n",
    "append_sent(traindf)\n",
    "append_sent(validdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89fbca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8849c11461494eb217a5cab0d032d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072e7c2393084da59bbd3fb0f53e28cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5558a40f1014df5bda2df3fac299208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concatenate conversations\n",
    "def concate_conv(df):\n",
    "    df_concat = pd.DataFrame(columns=df.columns) \\\n",
    "                .drop(['utterance_idx'], axis=1) \\\n",
    "                .rename(columns={'utterance': 'conv'})\n",
    "\n",
    "    conv_id_groups = df.groupby(['conv_id'])\n",
    "\n",
    "    for _, indices in tqdm(conv_id_groups.groups.items()):\n",
    "        conv_rows = df.loc[indices].copy().sort_values(['utterance_idx'])\n",
    "        conv_row = conv_rows.iloc[0].drop(['utterance_idx']).rename({'utterance': 'conv'})\n",
    "#         conv_row['prompt'] = '[CLS] ' + conv_row['prompt'] + ' [SEP]'\n",
    "#         conv_row['conv'] = '[CLS] ' + ' [SEP] '.join(conv_rows['utterance'].values)\n",
    "        conv_row['conv'] = ' [SEP] '.join(conv_rows['utterance'].values)\n",
    "        df_concat = df_concat.append(conv_row, ignore_index=True)\n",
    "        \n",
    "    return df_concat\n",
    "\n",
    "_traindf = concate_conv(traindf)\n",
    "_validdf = concate_conv(validdf)\n",
    "_testdf = concate_conv(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e34ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_traindf.to_csv('data/new_train.csv', index=False, encoding='utf8')\n",
    "_validdf.to_csv('data/new_valid.csv', index=False, encoding='utf8')\n",
    "_testdf.to_csv('data/new_test.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11b153",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### Training data\n",
    "- [x] count each label, check classes imbalance\n",
    "- [x] check the words with high frequencies for each label\n",
    "- [x] check the label similarities (maybe by common words counts)\n",
    "\n",
    "### Validation data\n",
    "- [ ] count each label, check classes imbalance\n",
    "- [ ] check the words with high frequencies for each label\n",
    "- [ ] check the label similarities (maybe by common words counts)\n",
    "- [ ] check OOV\n",
    "\n",
    "### Testing data\n",
    "- [ ] check OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c5ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sent_tiers = pd.DataFrame(_traindf.value_counts(subset=['sent']), columns=['count']) \\\n",
    "            .sort_values('count').reset_index()\n",
    "px.bar(sent_tiers, x='count', y='sent', color='count', labels={'sent': 'sentiment'},\n",
    "       title='Label Counts', width=800, height=800,\n",
    "       color_continuous_scale=px.colors.sequential.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e56dab",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Well, not quite imbalanced. But the samples with `surprised` label are far more than others. We may need data augmentation for other labels excluding `surprised` label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "vocab = set()\n",
    "prompt_tokens, conv_tokens = list(), list()\n",
    "\n",
    "for prompt in _traindf['prompt'].values:\n",
    "    tokens = prompt.split()\n",
    "    vocab = vocab.union(set(tokens))\n",
    "    prompt_tokens.append(tokens)\n",
    "    \n",
    "for conv in _traindf['conv'].values:\n",
    "    tokens = conv.split()\n",
    "    vocab = vocab.union(set(tokens))\n",
    "    conv_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "seqlens_prompt = np.array([len(tokens) for tokens in prompt_tokens])\n",
    "print(f'# of vocab: {len(vocab)}')\n",
    "print('=== Tokenized Prompt Corpus ===')\n",
    "print(f'max sequence length: {seqlens_prompt.max()}')\n",
    "print(f'min sequence length: {seqlens_prompt.min()}')\n",
    "print(f'avg sequence length: {seqlens_prompt.mean()}\\n')\n",
    "\n",
    "seqlens_conv = np.array([len(tokens) for tokens in conv_tokens])\n",
    "print('=== Tokenized Conversation Corpus ===')\n",
    "print(f'max sequence length: {seqlens_conv.max()}')\n",
    "print(f'min sequence length: {seqlens_conv.min()}')\n",
    "print(f'avg sequence length: {seqlens_conv.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f85a4",
   "metadata": {},
   "source": [
    "ðŸ’¡ **There's no text is longer than 512 which is the max length that BERT can receive.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "palette = iter([plt.cm.Accent(i) for i in range(10)])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist([len(prompt) for prompt in prompt_tokens], range=(1, 111), color=next(palette))\n",
    "plt.title('Prompt Corpus Sequences Length Histogram', fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist([len(conv) for conv in conv_tokens], range=(1, 393), color=next(palette))\n",
    "plt.title('Conversation Corpus Sequences Length Histogram', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_traindf[_traindf['label'] == 2]['conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5dee0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count word frequencies for each label\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stpw = stopwords.words('english')\n",
    "\n",
    "sent_freq_dict = dict()\n",
    "for label, sent in id_sent.items():\n",
    "    freq_dict = dict()\n",
    "    for text in _traindf[_traindf['label'] == label]['conv'].values:\n",
    "        tokens = text.split()\n",
    "        for token in tokens:\n",
    "            if token not in {'[CLS]', '[SEP]'} and token not in stpw:\n",
    "                freq_dict[token] = freq_dict.get(token, 0)+1\n",
    "    sent_freq_dict[sent] = freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a2398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets see how the words are distributed in each label\n",
    "sent_top20words = dict()\n",
    "for label, sent in id_sent.items():\n",
    "    top20_words = [k for k, v in sorted(sent_freq_dict[sent].items(), key=lambda x: x[1], reverse=True)][:20]\n",
    "    sent_top20words[sent] = top20_words\n",
    "    print(f'{sent}:\\n{top20_words}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb41d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply check the similarities between each two labels by top20 words cooccurrance\n",
    "# or we can enhance this analysis by tf-idf score\n",
    "n_labels = _traindf['label'].nunique()\n",
    "\n",
    "sim_matrix = np.empty(shape=(n_labels, n_labels))\n",
    "for i in range(n_labels):\n",
    "    for j in range(n_labels):\n",
    "        if i == j:\n",
    "            sim_matrix[i, j] = 20  # the two same labels get full score 20\n",
    "        \n",
    "        sent_i_words = set(sent_top20words[id_sent[i]])\n",
    "        sent_j_words = set(sent_top20words[id_sent[j]])\n",
    "        sim_matrix[i, j] = len(sent_i_words.intersection(sent_j_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcfb25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "ax = fig.add_subplot(111)\n",
    "matplot = ax.matshow(sim_matrix)\n",
    "fig.colorbar(matplot, fraction=0.044)\n",
    "ax.set_xticks(list(id_sent.keys()), list(id_sent.values()), rotation=-90, fontsize=12)\n",
    "ax.set_yticks(list(id_sent.keys()), list(id_sent.values()), fontsize=12)\n",
    "ax.set_title('Sentiment Similarity Matrix', fontdict=dict(fontsize=24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564064cf",
   "metadata": {},
   "source": [
    "ðŸ’¡ **Indeed, There are some labels are similar. e.g. anxious & conprehensive, afraid & terrified.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
