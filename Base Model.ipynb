{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8bNCJ8dDY-l"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4C4FdL3C4ErW"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/MyDrive/NYCU NLP Final/')\n",
    "sys.path.append('/content/drive/MyDrive/NYCU NLP Final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBLNYZK0DaqO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHDI6cYj6a0J"
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union, Callable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vr52razv38Am"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "SEED = 42\n",
    "\n",
    "MODEL_NAME='distilroberta-base'\n",
    "HIDDEN_DROPOUT = 0.1\n",
    "DROPOUT = 0.2\n",
    "\n",
    "EPOCHS=10\n",
    "TRAIN_BATCH_SIZE=16\n",
    "VALID_BATCH_SIZE=64\n",
    "\n",
    "MODEL_SAVE_DIR = '0610_base_test'\n",
    "# CHECKPOINT = 'checkpoint-4884'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YtkZFM5AeR1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiPavzo838Ao"
   },
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uijxITXR38Ap"
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('data/new_train.csv')\n",
    "validdf = pd.read_csv('data/new_valid.csv')\n",
    "testdf = pd.read_csv('data/new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tqj0GekSEi-z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'# train: {len(traindf)}')\n",
    "print(f'# valid: {len(validdf)}')\n",
    "print(f'# test: {len(testdf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHzktRKB38Ap"
   },
   "outputs": [],
   "source": [
    "classes = traindf['label'].unique()\n",
    "n_labels = len(classes)\n",
    "\n",
    "sent_id = {\n",
    "    'sad':      0,  'trusting':     1,  'terrified': 2,  'caring':      3,  'disappointed': 4, \n",
    "    'faithful': 5,  'joyful':       6,  'jealous':   7,  'disgusted':   8,  'surprised':    9, \n",
    "    'ashamed':  10, 'afraid':       11, 'impressed': 12, 'sentimental': 13, 'devastated':   14, \n",
    "    'excited':  15, 'anticipating': 16, 'annoyed':   17, 'anxious':     18, 'furious':      19, \n",
    "    'content':  20, 'lonely':       21, 'angry':     22, 'confident':   23, 'apprehensive': 24, \n",
    "    'guilty':   25, 'embarrassed':  26, 'grateful':  27, 'hopeful':     28, 'proud':        29, \n",
    "    'prepared': 30, 'nostalgic':    31\n",
    "}\n",
    "\n",
    "id_sent = {v: k for k, v in sent_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY01-xchq_9u",
    "outputId": "6681c51d-67ed-4c28-cfa9-8610de82bb3f"
   },
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDFHMLxU38Ar",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class PromptConvDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, df, tokenizer: PreTrainedTokenizerBase):\n",
    "#         self.size = len(df)\n",
    "#         self.encoded_dict = tokenizer(df[['prompt', 'conv']].values.tolist(), \n",
    "#                                       add_special_tokens=True, \n",
    "#                                       padding=True, \n",
    "#                                       truncation=True)\n",
    "        \n",
    "#         if 'label' in df.columns:\n",
    "#             self.labels = df['label'].values.tolist()\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {k: torch.tensor(v[idx]) for k, v in self.encoded_dict.items()}\n",
    "\n",
    "#         if self.labels:\n",
    "#             item['labels'] = torch.tensor(self.labels[idx])\n",
    "        \n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "\n",
    "class PromptConvDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.size = len(df)\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx][['prompt', 'conv']].values.tolist()\n",
    "\n",
    "        if self.transform:\n",
    "            encoding = self.transform(item)  # encoded dict\n",
    "            item = {k: torch.tensor(v) for k, v in encoding.items()}\n",
    "\n",
    "        if 'label' in self.df.columns:\n",
    "            item['labels'] = torch.tensor(self.df.iloc[idx]['label'])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixMU03DssHxT"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "special_tokens_dict = {'additional_special_tokens': ['[SPEAKER_A]', '[SPEAKER_B]']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX8crtsc4q0H"
   },
   "outputs": [],
   "source": [
    "from transforms import (\n",
    "    Tokenization,\n",
    "    RandomDeletion,\n",
    "    RandomSwap,\n",
    "    RandomMask,\n",
    "    Encoding\n",
    ")\n",
    "\n",
    "encoding = torch.nn.Sequential(\n",
    "    Tokenization(tokenizer),\n",
    "    Encoding(tokenizer, max_length=512)\n",
    ")\n",
    "\n",
    "augmentation = torch.nn.Sequential(\n",
    "    Tokenization(tokenizer),\n",
    "    RandomDeletion(tokenizer, rate=0.1),\n",
    "    RandomSwap(tokenizer, n_swap=1),\n",
    "    RandomMask(tokenizer, rate=0.1),\n",
    "    Encoding(tokenizer, max_length=512)\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = PromptConvDataset(traindf, encoding) # to get augmentated data, just replace the encoding with augmentation\n",
    "valid_dataset = PromptConvDataset(validdf, encoding)\n",
    "test_dataset = PromptConvDataset(testdf, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGAa3P_yHAtw"
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric_precision = load_metric('precision')\n",
    "metric_recall = load_metric('recall')\n",
    "metric_f1 = load_metric('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = metric_precision.compute(predictions=predictions, references=labels, average='macro')['precision']\n",
    "    recall = metric_recall.compute(predictions=predictions, references=labels, average='macro')['recall']\n",
    "    f1_score = metric_f1.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    return {'Precision': precision, 'Recall': recall, 'F1': f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auZZvYFbQlbf"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7tVBPo938At",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load raw model\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME, \n",
    "                                    hidden_dropout_prob=HIDDEN_DROPOUT, \n",
    "                                    classifier_dropout=DROPOUT,\n",
    "                                    num_labels=n_labels,\n",
    "                                    id2label=id_sent,\n",
    "                                    label2id=sent_id)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3T_xvBM-s6wz"
   },
   "outputs": [],
   "source": [
    "# load fine-tuned model\n",
    "# from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(os.path.join(MODEL_SAVE_DIR, CHECKPOINT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0HAE--ARG_g"
   },
   "source": [
    "## Build Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qh3UGZ2G38Au"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_SAVE_DIR,\n",
    "    logging_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_steps=1000,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"F1\",\n",
    "    seed=SEED,\n",
    "    data_seed=SEED\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYbLS28sBkUb"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOP7e99o38Av",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLOg3ouKGka4"
   },
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlnXX0-15fTU"
   },
   "outputs": [],
   "source": [
    "def post_processing(logits, threshold: float = 1., steps: int = 0):\n",
    "    \"\"\"Replace the top1 prediction with other potential candidates. \n",
    "    Setting threshold=1 and steps=0 will always take the top1 candidate as the answer.\n",
    "\n",
    "    Args:\n",
    "        logits (Union[List, np.array]): the output hypothesis of the model\n",
    "        threshold (float): if top2 > top1 * threshold then the second candidate will be the result\n",
    "        steps (int): how many candidates should be test\n",
    "    \"\"\"\n",
    "    n_data, n_classes = logits.shape\n",
    "    logits = torch.softmax(torch.tensor(logits), dim=-1)\n",
    "    top5_indices = torch.argsort(logits, dim=-1, descending=True)[:, :5] # top 5 label predictions\n",
    "    result = top5_indices[:, 0].clone() # label predictions\n",
    "\n",
    "    # default result is just argmax, no candidates will be checked\n",
    "    if threshold == 1 and steps == 0:\n",
    "        return result\n",
    "    \n",
    "    # check if the second ans satisfies the threshold\n",
    "    for i in range(n_data):\n",
    "        if logits[i, top5_indices[i, 1]] > logits[i, top5_indices[i, 0]] * threshold:\n",
    "            result[i] = top5_indices[i, 1]\n",
    "\n",
    "    return result\n",
    "\n",
    "def evaluate_f1(preds, labels, average='macro'):\n",
    "    precision = metric_precision.compute(predictions=preds, references=labels, average=average)['precision']\n",
    "    recall = metric_recall.compute(predictions=preds, references=labels, average=average)['recall']\n",
    "    f1_score = metric_f1.compute(predictions=preds, references=labels, average=average)['f1']\n",
    "    return {'Precision': precision, 'Recall': recall, 'F1': f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCfjCke7DuuI"
   },
   "outputs": [],
   "source": [
    "eval_preds = trainer.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyF9U6vwQF4e"
   },
   "outputs": [],
   "source": [
    "preds = post_processing(eval_preds.predictions)\n",
    "valid_f1 = evaluate_f1(preds, eval_preds.label_ids, average=None)['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaeBbddhyq9O"
   },
   "outputs": [],
   "source": [
    "test_preds = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_iOG9b12uwP"
   },
   "outputs": [],
   "source": [
    "test_ans = post_processing(test_preds.predictions)\n",
    "testdf['pred'] = test_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeNRssvp6QNr"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/fixed_test.csv')\n",
    "submission['pred'] = np.zeros(shape=(len(submission),))\n",
    "for _, row in testdf.iterrows():\n",
    "    submission.loc[(submission['conv_id'] == row['conv_id']), 'pred'] = row['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYeUX2p47Y80"
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDPpBxjI8p2Z"
   },
   "outputs": [],
   "source": [
    "submission[['pred']].to_csv(f'output/20220526_ckpt{CHECKPOINT.split('-')[-1]}_submission.csv', encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Y8bNCJ8dDY-l",
    "WiPavzo838Ao",
    "JY01-xchq_9u",
    "QLOg3ouKGka4"
   ],
   "name": "Base Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
